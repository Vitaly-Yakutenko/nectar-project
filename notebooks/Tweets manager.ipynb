{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queues_cfg = cfg['QUEUES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_queue_path = queues_cfg['new_tweets']\n",
    "processed_tweets_path = queues_cfg['processed_tweets']\n",
    "sa_queue_path = queues_cfg['sentiment_tasks']\n",
    "geo_queue_path = queues_cfg['geo_tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for folder in [tweets_folder, sentiment_folder, geo_folder, 'tweet_no_coordinates']:\n",
    "for folder in [tweets_queue_path, processed_tweets_path, ]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56139"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_tweets = glob('{}/*.json'.format(tweets_queue_path))\n",
    "len(unprocessed_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Downloaded Tweets Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geoanalyser_task(tweet_id, coordinates):\n",
    "    filename = '{}/{}.task.txt'.format(geo_queue_path, tweet_id)\n",
    "    with open(filename, 'w') as fp:\n",
    "        fp.write(json.dumps(coordinates))\n",
    "        fp.close()\n",
    "\n",
    "def send_to_geoanalyser(tweet_id, tweet_json):\n",
    "    try:\n",
    "        if tweet_json['coordinates'] is not None:\n",
    "            coordinates = tweet_json['coordinates']\n",
    "        elif tweet_json['place'] is not None:\n",
    "            coordinates = tweet_json['place']['bounding_box']\n",
    "        else:\n",
    "            print('Tweet {} doesn\\'t contain coordinates'.format(tweet_id))\n",
    "            print(path)\n",
    "        create_geoanalyser_task(tweet_id, coordinates=coordinates)\n",
    "    except Exception as e:\n",
    "        print('Tweet {} wasn\\'t sent to geoanalyser due to error. {}'.format(tweet_id, e))\n",
    "        #raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_task(tweet_id, text):\n",
    "    filename = '{}/{}.task.txt'.format(sa_queue_path, tweet_id)\n",
    "    with open(filename, 'w') as fp:\n",
    "        fp.write(text)\n",
    "        fp.close()\n",
    "        \n",
    "def send_to_sentiment_analysis(tweet_id, tweet_json):\n",
    "    try:\n",
    "        if tweet_json['text'] is not None:\n",
    "            text = tweet_json['text']\n",
    "        else:\n",
    "            print('Tweet {} doesn\\'t contain text'.format(tweet_id))\n",
    "            print(path)\n",
    "        create_sentiment_task(tweet_id, text)\n",
    "    except Exception as e:\n",
    "        print('Tweet {} wasn\\'t sent to sentiment analyser due to error. {}'.format(tweet_id, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_couch_db(path):\n",
    "    filename = path.split('/')[-1]\n",
    "    new_path = '{}/{}'.format(processed_tweets_path, filename)\n",
    "    shutil.move(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $processed_tweets_path/* $tweets_queue_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tFile processed: 5\n",
      "Iteration: 2\tFile processed: 4\n",
      "Iteration: 3\tFile processed: 5\n",
      "Iteration: 4\tFile processed: 11\n",
      "Iteration: 5\tFile processed: 6\n",
      "Iteration: 6\tFile processed: 11\n"
     ]
    }
   ],
   "source": [
    "#for path in bitcoin_pathes:\n",
    "i = 1\n",
    "while True:\n",
    "    unprocessed_tweets = glob('{}/*.json'.format(tweets_queue_path))\n",
    "    for path in unprocessed_tweets:\n",
    "        with open(path, 'r') as fp:\n",
    "            tweet_json = json.load(fp)\n",
    "            tweet_id = tweet_json['id_str']\n",
    "            for analyser_func in (send_to_geoanalyser, send_to_sentiment_analysis):\n",
    "                analyser_func(tweet_id, tweet_json)\n",
    "            save_to_couch_db(path)\n",
    "    \n",
    "    print('Iteration: {}\\tFiles processed: {}'.format(i, len(unprocessed_tweets)))\n",
    "    i+=1\n",
    "    time.sleep(20)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../shared_folder/tweets/988986510979497985.json', 'r') as fp:\n",
    "    data = json.load(fp)   \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse tweets contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = ['bitcoin', 'blockchain', 'btc', 'cryptocurrency', 'market\\svalue',\n",
    "            'crypto','ethereum', 'fintech', 'coin', 'doge', 'ethereum', 'ripple', 'litecoin', \n",
    "            'cardano', 'monero', 'TRON', 'zcash', 'jaxx', 'copay', 'bitpay', 'exodus', \n",
    "            'mycelium', 'Bread\\sWallet', 'trezor', 'ledger\\snano', 'Silk\\sRoad', 'darknet\\smarket', \n",
    "            'dogecoin', 'ASIC\\sMiner', 'Central\\sLedger', 'Hashrate', 'ICO',         \n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bitcoin|blockchain|btc|cryptocurrency|market\\\\svalue|crypto|ethereum|fintech|coin|doge|ethereum|ripple|litecoin|cardano|monero|TRON|zcash|jaxx|copay|bitpay|exodus|mycelium|Bread\\\\sWallet|trezor|ledger\\\\snano|Silk\\\\sRoad|darknet\\\\smarket|dogecoin|ASIC\\\\sMiner|Central\\\\sLedger|Hashrate|ICO'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_pathes = []\n",
    "for path in (unprocessed_tweets):\n",
    "    with open(path, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        if re.search('|'.join(hashtags), json.dumps(data)):\n",
    "            bitcoin_pathes.append(path)\n",
    "        #print(data['entities']['hashtags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bitcoin_pathes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
