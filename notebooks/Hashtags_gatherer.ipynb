{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEARCH API\n",
    "import ijson\n",
    "import tweepy\n",
    "#import TwitterCredentials as twit\n",
    "import jsonpickle\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "os.chdir('../')\n",
    "\n",
    "with open(\"config.yaml\", 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "    ymlfile.close()\n",
    "\n",
    "twitter_cfg = cfg['TWEETER']\n",
    "queues_cfg = cfg['QUEUES']\n",
    "new_tweets_queue = queues_cfg['new_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= \"sZMPWW0zCEVsHnDyO950hWEWN\"\n",
    "consumer_secret= \"KfS6UNO3cTCC6j5xHfjQGaNzBFofDRN98pm5aguCvduIr0UQpg\"                  \n",
    "access_token_key= \"1397965644-WVAG6QSXEBCdHtyAeEgBsKYXEKlkoBBtb58oOAN\"  \n",
    "access_token_secret= \"V6V2aUVFmUwkUcHhFzOn4XnwdkbCJPLOL65ZSEnRe9d7O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethereum\n",
      "Downloaded 98 tweets\n",
      "Downloaded 198 tweets\n",
      "Downloaded 281 tweets\n",
      "Downloaded 370 tweets\n",
      "Downloaded 468 tweets\n",
      "Downloaded 559 tweets\n",
      "Downloaded 647 tweets\n",
      "Downloaded 747 tweets\n",
      "Downloaded 846 tweets\n",
      "Downloaded 932 tweets\n",
      "Downloaded 1022 tweets\n",
      "Downloaded 1114 tweets\n",
      "Downloaded 1210 tweets\n",
      "Downloaded 1289 tweets\n",
      "Downloaded 1382 tweets\n",
      "Downloaded 1482 tweets\n",
      "Downloaded 1578 tweets\n",
      "Downloaded 1678 tweets\n",
      "Downloaded 1759 tweets\n",
      "Downloaded 1856 tweets\n",
      "Downloaded 1946 tweets\n",
      "Downloaded 2046 tweets\n",
      "Downloaded 2146 tweets\n",
      "Downloaded 2235 tweets\n",
      "Downloaded 2335 tweets\n",
      "Downloaded 2435 tweets\n",
      "Downloaded 2530 tweets\n",
      "Downloaded 2630 tweets\n",
      "Downloaded 2723 tweets\n",
      "Downloaded 2818 tweets\n",
      "Downloaded 2915 tweets\n",
      "Downloaded 3008 tweets\n",
      "Downloaded 3104 tweets\n",
      "Downloaded 3204 tweets\n",
      "Downloaded 3296 tweets\n",
      "Downloaded 3396 tweets\n",
      "Downloaded 3487 tweets\n",
      "Downloaded 3587 tweets\n",
      "Downloaded 3679 tweets\n",
      "Downloaded 3777 tweets\n",
      "Downloaded 3864 tweets\n",
      "Downloaded 3964 tweets\n",
      "Downloaded 4062 tweets\n",
      "Downloaded 4157 tweets\n",
      "Downloaded 4247 tweets\n",
      "Downloaded 4342 tweets\n",
      "No more tweets found\n",
      "bdoge\n",
      "No more tweets found\n",
      "litecoin\n",
      "No more tweets found\n",
      "btron\n",
      "No more tweets found\n",
      "copay\n",
      "No more tweets found\n",
      "bitpay\n",
      "No more tweets found\n",
      "mycelium\n",
      "No more tweets found\n",
      "trezor\n",
      "No more tweets found\n",
      "altcoin\n",
      "No more tweets found\n",
      "blockchain\n",
      "No more tweets found\n",
      "bitcoin\n",
      "No more tweets found\n",
      "Downloaded 0 tweets, Saved to extra_tweets.json\n"
     ]
    }
   ],
   "source": [
    "keywords = [#'bcoin', \n",
    "'ethereum', 'bdoge',\n",
    "'litecoin',\n",
    "'btron',\n",
    "'copay',\n",
    "'bitpay',\n",
    "'mycelium',\n",
    "'trezor',\n",
    "'altcoin','blockchain', 'bitcoin',]\n",
    "\n",
    "\n",
    "tweetsPerQry = 100\n",
    "fName = 'extra_tweets.json'\n",
    "sinceId = None\n",
    "max_id = -1\n",
    "\n",
    "#australia = [[109.94541423022338,-9.67869330662115],[155.03330484714022,-9.67869330662115],[155.03330484714022,-39.93552098705151],[109.94541423022338,-39.93552098705151]]\n",
    "#Geobox_australia = Polygon(australia)\n",
    "\n",
    "\n",
    "#print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "for searchQuery in keywords:\n",
    "    print (searchQuery)\n",
    "    tweetCount = 0\n",
    "    maxTweets = 1000000\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, lang=\"en\", geocode=\"-26.0,134.0,3000km\", count=tweetsPerQry)\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, lang=\"en\", geocode=\"-26.0,134.0,3000km\", count=tweetsPerQry, since_id=sinceId)\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, lang=\"en\", geocode=\"-26.0,134.0,3000km\", count=tweetsPerQry,max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, lang=\"en\", geocode=\"-26.0,134.0,3000km\", count=tweetsPerQry, max_id=str(max_id - 1), since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                tweet_id = tweet._json['id_str']\n",
    "                filename = '{}/{}.json'.format(new_tweets_queue, tweet_id)\n",
    "                with open(filename, 'w') as tweet_fp:\n",
    "                    json.dump(tweet._json, tweet_fp)\n",
    "                #print('Tweet {} was successfully queued to {}'.format(tweet_id, filename))\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "        time.sleep(10)\n",
    "\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
